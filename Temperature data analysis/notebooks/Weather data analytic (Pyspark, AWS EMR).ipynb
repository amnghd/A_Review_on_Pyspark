{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather Data Analytics:\n",
    "\n",
    "In this notebook, we are working on a weather data set performing different analytic actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting codes/min_temperature.py\n"
     ]
    }
   ],
   "source": [
    "%%file codes/min_temperature.py\n",
    "\n",
    "import findspark\n",
    "findspark.init() # adding pyspark on the sys.path at the run time\n",
    "from pyspark import SparkConf, SparkContext\n",
    "# setting up spark\n",
    "conf = SparkConf().setMaster('local').setAppName('Minimum_temprature')\n",
    "sc = SparkContext(conf = conf)\n",
    "# importing the data\n",
    "lines = sc.textFile('file:///Users/Amin/Dropbox/Career Deveoment/Data Science/PySpark/Temperature data analysis/data/raw/1800.csv')\n",
    "# defining the text parse\n",
    "def parser(line):\n",
    "    try: # while data is in correct format\n",
    "        data = line.strip().split(',')\n",
    "        station = data[0]\n",
    "        measure = data[2]\n",
    "        temp = float(data[3]) / 10 # conerting temperature to 1 deg celcius\n",
    "        return station, measure, temp\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "# performing the query\n",
    "parsed_lines = lines.map(parser)\n",
    "filtered_data = parsed_lines.filter(lambda x: x[1] == 'TMIN').map(lambda x: (x[0],x[2]))\n",
    "tempBystation = filtered_data.reduceByKey(min)\n",
    "\n",
    "# getting the results\n",
    "results = tempBystation.collect()\n",
    "# reporting the results\n",
    "for res in results:\n",
    "    print(res[0], ':\\t', res[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITE00100554 :\t -14.8\n",
      "EZE00100082 :\t -13.5\n",
      "SUCCESS: The process with PID 21316 (child process of PID 20112) has been terminated.\n",
      "SUCCESS: The process with PID 20112 (child process of PID 16224) has been terminated.\n",
      "SUCCESS: The process with PID 16224 (child process of PID 19056) has been terminated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19/03/10 19:11:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "\n",
      "[Stage 0:>                                                          (0 + 1) / 1]\n",
      "[Stage 1:>                                                          (0 + 1) / 1]\n",
      "                                                                                \n"
     ]
    }
   ],
   "source": [
    "!python codes/min_temperature.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
